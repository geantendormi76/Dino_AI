# training_pipelines/3_policy_pipeline/3_train_and_export.py
import sys
from pathlib import Path
import numpy as np
import torch
from d3rlpy.algos import DiscreteCQLConfig
from d3rlpy.datasets import MDPDataset
from d3rlpy.logging import CombineAdapterFactory, FileAdapterFactory, TensorboardAdapterFactory
from d3rlpy.metrics import TDErrorEvaluator, AverageValueEstimationEvaluator

project_root = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(project_root))

# --- [æ ¸å¿ƒä¿®æ”¹] æ›´æ–°æ‰€æœ‰è·¯å¾„ ---
DATASET_PATH = project_root / "data" / "policy_data" / "processed" / "iql_dataset.npz"
LOG_DIR_BASE = project_root / "training_runs" # å°†æ‰€æœ‰è®­ç»ƒæ—¥å¿—ç»Ÿä¸€å­˜æ”¾
EXPERIMENT_NAME = "policy_run"
ONNX_MODEL_PATH = project_root / "models" / "policy" / "dino_policy.onnx"
ONNX_MODEL_PATH.parent.mkdir(exist_ok=True)

TRAIN_STEPS, STEPS_PER_EPOCH, SAVE_INTERVAL_IN_EPOCHS = 200000, 10000, 2

def main():
    print(f"ğŸ§  å¼€å§‹æ‰§è¡Œâ€œä¸€é”®å¼â€è®­ç»ƒä¸å¯¼å‡ºæµç¨‹...")
    
    # 1. åŠ è½½æ•°æ®é›†
    try:
        data = np.load(DATASET_PATH)
        dataset = MDPDataset(
            observations=data['observations'], actions=data['actions'],
            rewards=data['rewards'], terminals=data['terminals'],
        )
        print(f"âœ… æˆåŠŸåŠ è½½å¹¶æ„å»ºæ•°æ®é›†: {DATASET_PATH}")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶ {DATASET_PATH}ã€‚è¯·å…ˆè¿è¡Œ 2_process_data.pyã€‚")
        return
        
    # 2. é…ç½® DiscreteCQL
    cql_config = DiscreteCQLConfig(
        batch_size=256, gamma=0.99, learning_rate=1e-4, alpha=1.0, n_critics=2,
    )

    # 3. åˆ›å»ºå®ä¾‹
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")
    cql = cql_config.create(device=device)

    # 4. é…ç½®æ—¥å¿—
    logger = CombineAdapterFactory([
        FileAdapterFactory(root_dir=str(LOG_DIR_BASE)),
        TensorboardAdapterFactory(root_dir=str(LOG_DIR_BASE))
    ])
    
    # 5. é…ç½®è¯„ä¼°å™¨
    evaluators = { 'td_error': TDErrorEvaluator(), 'avg_value': AverageValueEstimationEvaluator() }
    
    # 6. å¼€å§‹è®­ç»ƒ
    print("ğŸš€ æ­£åœ¨å¯åŠ¨è®­ç»ƒ... ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨TensorBoardæ¥å®æ—¶ç›‘æ§ï¼š")
    print(f"   tensorboard --logdir {LOG_DIR_BASE}")
    
    cql.fit(
        dataset, n_steps=TRAIN_STEPS, n_steps_per_epoch=STEPS_PER_EPOCH,
        save_interval=SAVE_INTERVAL_IN_EPOCHS, logger_adapter=logger,
        experiment_name=EXPERIMENT_NAME, with_timestamp=False, evaluators=evaluators,
    )
    
    # 7. å¯¼å‡ºæœ€ç»ˆæ¨¡å‹
    final_model_dir = LOG_DIR_BASE / EXPERIMENT_NAME
    print(f"ğŸ’¾ è®­ç»ƒå®Œæˆï¼Œæ­£åœ¨å°†æœ€ç»ˆç­–ç•¥å¯¼å‡ºä¸º ONNX æ ¼å¼åˆ° {ONNX_MODEL_PATH}...")
    cql.save_policy(str(ONNX_MODEL_PATH))
    
    print("\n" + "="*50)
    print("ğŸ‰ğŸ‰ğŸ‰ â€œä¸€é”®å¼â€æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼ä½ çš„æœ€ä¼˜ä¸“å®¶å¤§è„‘å·²æˆåŠŸé“¸é€ ï¼ ğŸ‰ğŸ‰ğŸ‰")
    print(f"æœ€ç»ˆäº§å‡º: {ONNX_MODEL_PATH}")
    print("ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥æ»¡æ€€ä¿¡å¿ƒåœ°å»è¿è¡Œæœ€ç»ˆçš„ run_bot.py äº†ï¼")
    print("="*50)

if __name__ == "__main__":
    main()