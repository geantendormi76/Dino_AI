# run_bot.py (L3+ å†³ç­–Transformer ç‰ˆæœ¬)
import sys
from pathlib import Path
import cv2
import mss
import time
import numpy as np
import onnxruntime as ort
from collections import deque

# ä¿®æ­£Pythonæ¨¡å—æœç´¢è·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

# --- å¯¼å…¥æ–°çš„L3+æ ¸å¿ƒæ¨¡å— ---
from src.perception.fuser import PerceptionFuser
from src.world_modeling.state_representation import StateRepresentationBuilder
from src.utils.screen_manager import ScreenManager
from src.controls.agent import GameAgent
from src.contracts import Action # å¼•å…¥åŠ¨ä½œæšä¸¾

def main():
    print("ğŸš€ å¯åŠ¨ Dino AI (L3+ å†³ç­–Transformer å¤§è„‘)...")

    # --- 1. åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å— ---
    try:
        fuser = PerceptionFuser()
        state_builder = StateRepresentationBuilder()
        agent = GameAgent()
        screen_manager = ScreenManager(mss.mss())
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šåˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—å¤±è´¥: {e}")
        return

    # --- 2. åŠ è½½æ–°çš„å†³ç­–Transformer ONNXæ¨¡å‹ ---
    onnx_model_path = "models/policy/dino_decision_transformer.onnx"
    print(f"ğŸ§  æ­£åœ¨åŠ è½½å†³ç­–Transformerå¤§è„‘: {onnx_model_path}")
    try:
        # è¿™é‡Œçš„ provider é…ç½®å¯ä»¥å¤ç”¨ä½ ä¹‹å‰æˆåŠŸçš„TensorRTé…ç½®
        providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
        ort_session = ort.InferenceSession(onnx_model_path, providers=providers)
        print(f"âœ… å†³ç­–Transformerå¤§è„‘åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {ort_session.get_providers()}")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šåŠ è½½ONNXæ¨¡å‹å¤±è´¥: {e}")
        return

    # --- 3. åˆå§‹åŒ–ä¸Šä¸‹æ–‡åºåˆ— (AIçš„çŸ­æœŸè®°å¿†) ---
    # è¿™ä¸ªé•¿åº¦å¿…é¡»ä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„ä¸Šä¸‹æ–‡é•¿åº¦(max_len)å®Œå…¨ä¸€è‡´
    CONTEXT_LEN = 20
    state_deque = deque(maxlen=CONTEXT_LEN)
    action_deque = deque(maxlen=CONTEXT_LEN)
    rtg_deque = deque(maxlen=CONTEXT_LEN)
    timestep_deque = deque(maxlen=CONTEXT_LEN)

    # --- 4. æ¸¸æˆä¸ä¸»å¾ªç¯è®¾ç½® ---
    screen_manager.select_roi()
    if screen_manager.roi is None:
        print("ğŸ”´ æœªé€‰æ‹©æ¸¸æˆåŒºåŸŸï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    print("3ç§’åæœºå™¨äººå°†å¼€å§‹è¿è¡Œ...")
    time.sleep(3)
    
    # åˆå§‹ç›®æ ‡å›æŠ¥è®¾ä¸ºä¸€ä¸ªè¾ƒé«˜å€¼ï¼Œä¾‹å¦‚æœŸæœ›è·å¾—1000åˆ†
    # è¿™ä¸ªå€¼ä¼šéšç€æ—¶é—´é€’å‡
    target_return = 1000.0
    start_time = time.time()
    last_action = 0 # åˆå§‹åŠ¨ä½œä¸º "æ— æ“ä½œ"

    try:
        while True:
            frame_start_time = time.perf_counter()

            # --- a. æ„ŸçŸ¥ä¸çŠ¶æ€è¡¨ç¤º ---
            full_frame = screen_manager.capture()
            if full_frame is None: break
            
            fused_info = fuser.fuse(full_frame)
            state_repr = state_builder.build(fused_info)
            
            if state_repr is None:
                # æ¸¸æˆå¯èƒ½ç»“æŸæˆ–æœªå¼€å§‹ï¼Œè·³è¿‡å†³ç­–
                cv2.imshow("Dino AI - L3+ Brain (Debug View)", full_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'): break
                continue

            # --- b. æ›´æ–°ä¸Šä¸‹æ–‡åºåˆ— ---
            # æ³¨æ„ï¼šæˆ‘ä»¬ç”¨ä¸Šä¸€å¸§çš„åŠ¨ä½œæ¥å¡«å……å½“å‰å¸§çš„åŠ¨ä½œè¾“å…¥
            state_deque.append(state_repr)
            action_deque.append(last_action)
            rtg_deque.append(target_return)
            timestep = int(time.time() - start_time)
            timestep_deque.append(timestep)
            
            # ç®€å•åœ°è®©ç›®æ ‡å›æŠ¥éšæ—¶é—´è¡°å‡
            target_return = max(0, target_return - 0.1)

            # --- c. å‡†å¤‡æ¨¡å‹è¾“å…¥ (å¡«å……ä¸å¡‘å½¢) ---
            # å¦‚æœè®°å¿†è¿˜æœªå¡«æ»¡ï¼Œç”¨0è¿›è¡Œå·¦å¡«å……
            pad_len = CONTEXT_LEN - len(state_deque)
            
            input_grids = np.stack([s['arena_grid'] for s in state_deque])
            input_grids = np.pad(input_grids, ((pad_len, 0), (0, 0), (0, 0), (0, 0)), 'constant')

            # (åŒæ ·çš„æ–¹æ³•å¤„ç†å…¶ä»–è¾“å…¥)
            # ... (æ­¤å¤„çœç•¥äº†å¯¹ global_features, actions, rtgs, timesteps çš„å¡«å……ä»£ç ï¼Œè¯·åŠ¡å¿…è¡¥å…¨)
            # ... è¡¥å…¨ä»£ç  Start
            input_globals = np.stack([s['global_features'] for s in state_deque])
            input_globals = np.pad(input_globals, ((pad_len, 0), (0, 0)), 'constant')

            input_actions = np.array(list(action_deque), dtype=np.int64)
            input_actions = np.pad(input_actions, ((pad_len, 0)), 'constant')
            input_actions = np.eye(3)[input_actions] # è½¬ä¸º One-Hot

            input_rtgs = np.array(list(rtg_deque), dtype=np.float32).reshape(-1, 1)
            input_rtgs = np.pad(input_rtgs, ((pad_len, 0), (0, 0)), 'constant')
            
            input_timesteps = np.array(list(timestep_deque), dtype=np.int64).reshape(-1, 1)
            input_timesteps = np.pad(input_timesteps, ((pad_len, 0), (0, 0)), 'constant')
            # ... è¡¥å…¨ä»£ç  End


            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            input_grids = np.expand_dims(input_grids, axis=0).astype(np.float32)
            input_globals = np.expand_dims(input_globals, axis=0).astype(np.float32)
            input_actions = np.expand_dims(input_actions, axis=0).astype(np.float32)
            input_rtgs = np.expand_dims(input_rtgs, axis=0).astype(np.float32)
            input_timesteps = np.expand_dims(input_timesteps, axis=0).astype(np.int64)

            # --- d. æ¨¡å‹æ¨ç† ---
            input_dict = {
                'arena_grids': input_grids,
                'global_features': input_globals, # è®­ç»ƒè„šæœ¬ä¸­å¯èƒ½æœªä½¿ç”¨ï¼Œä½†æœ€å¥½ä¼ å…¥
                'actions': input_actions,
                'rtgs': input_rtgs,
                'timesteps': input_timesteps
            }
            
            # æ³¨æ„ï¼šONNXæ¨¡å‹çš„è¾“å…¥åå¿…é¡»ä¸å¯¼å‡ºæ—¶å®Œå…¨ä¸€è‡´
            # æˆ‘ä»¬éœ€è¦æ£€æŸ¥å¹¶è°ƒæ•´è¿™é‡Œçš„ key
            onnx_input_names = [inp.name for inp in ort_session.get_inputs()]
            # å‡è®¾ONNXè¾“å…¥åä¸º 'states_arena_grid', 'states_global_features', ...
            # è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„ONNXæ¨¡å‹è¿›è¡Œè°ƒæ•´
            onnx_inputs = {
                "arena_grids": input_grids,
                "global_features": input_globals, # <-- [å·²ä¿®æ­£] å¯ç”¨å…¨å±€ç‰¹å¾
                "actions": input_actions,
                "rtgs": input_rtgs, # <-- [å·²ä¿®æ­£] é”®åå¿…é¡»ä¸º 'rtgs'
                "timesteps": input_timesteps
            }

            action_logits = ort_session.run(None, onnx_inputs)[0]
            
            # æˆ‘ä»¬åªå…³å¿ƒåºåˆ—ä¸­æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œé¢„æµ‹
            action_index = np.argmax(action_logits[0, -1, :])

            # --- e. æ‰§è¡ŒåŠ¨ä½œ ---
            if action_index == Action.JUMP.value:
                agent.jump(duration=0.05)
            elif action_index == Action.DUCK.value:
                agent.duck()
            
            # æ›´æ–° last_action ç”¨äºä¸‹ä¸€è½®å¾ªç¯
            last_action = action_index

            # --- f. å¯è§†åŒ–ä¸é€€å‡º ---
            frame_end_time = time.perf_counter()
            print(f"Frame Time: {((frame_end_time - frame_start_time)*1000):.2f}ms | Action: {Action(action_index).name}")

            cv2.imshow("Dino AI - L3+ Brain (Debug View)", full_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    finally:
        cv2.destroyAllWindows()
        print("ğŸ¤– Dino AI (L3+) å·²åœæ­¢è¿è¡Œã€‚")

if __name__ == "__main__":
    main()