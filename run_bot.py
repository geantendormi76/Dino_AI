# run_bot.py (V15 - å†³ç­–é“¾æ¡è¯Šæ–­ & æœ€ç»ˆç¨³å®šç‰ˆ)
import sys
from pathlib import Path
import cv2
import mss
import time
import numpy as np
import onnxruntime as ort

project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.perception.detector import AdvancedDetector
from src.world_modeling.state import GameState
from src.world_modeling.world_model import UKFWorldModel
from src.utils.screen_manager import ScreenManager
from src.controls.agent import GameAgent
from src.state_builder import build_state_vector

def main():
    print("ğŸš€ å¯åŠ¨ Dino AI (ä¸“å®¶å¤§è„‘ - æœ€ç»ˆå†³æˆ˜ç‰ˆ)...")

    detector = None
    prev_time = time.time() 

    try:
        detector = AdvancedDetector(
            yolo_model_path="models/detection/dino_detector.onnx",
            classifier_model_path="models/classification/dino_classifier.pth"
        )
        game_state = GameState()
        world_model = UKFWorldModel()
        agent = GameAgent()
        screen_manager = ScreenManager(mss.mss())
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šåˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—å¤±è´¥: {e}")
        return

    # --- PyTorch Profiler å¯ç”¨ (è¯Šæ–­ç»“æŸåè¯·æ³¨é‡Šæˆ–ç§»é™¤) ---
    # detector.enable_profiler(log_dir="runs/classifier_profiler_logs")
    # ----------------------------------------------------

    onnx_model_path = "models/policy/dino_policy.onnx"
    print(f"ğŸ§  æ­£åœ¨åŠ è½½ä¸“å®¶å¤§è„‘: {onnx_model_path}")
    try:
        session_options = ort.SessionOptions()
        session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        trt_provider_options = {
            "trt_fp16_enable": True,
            "trt_cuda_graph_enable": False, # æš‚æ—¶ç¦ç”¨ CUDA Graphï¼Œå› ä¸ºæœªå®ç° I/O Binding
            "trt_engine_cache_enable": True,
            "trt_engine_cache_path": str(project_root / "models" / "onnx_cache"),
            "trt_max_workspace_size": 2147483648, # 2GB æ˜¾å­˜å·¥ä½œåŒº
        }
        
        providers = [
            ("TensorrtExecutionProvider", trt_provider_options),
            "CUDAExecutionProvider",
            "CPUExecutionProvider",
        ]

        ort_session = ort.InferenceSession(
            onnx_model_path,
            sess_options=session_options,
            providers=providers
        )
        
        (project_root / "models" / "onnx_cache").mkdir(parents=True, exist_ok=True)

        print(f"âœ… ä¸“å®¶å¤§è„‘åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {ort_session.get_providers()}")
        print("æ³¨æ„ï¼šç¬¬ä¸€æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢ï¼ŒTensorRTæ­£åœ¨æ„å»ºä¼˜åŒ–å¼•æ“å¹¶ç¼“å­˜ã€‚")

    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šåŠ è½½ONNXæ¨¡å‹å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ONNX Runtime GPUæ˜¯å¦æ­£ç¡®å®‰è£…ï¼Œä»¥åŠTensorRTç›¸å…³åº“æ˜¯å¦å¯ç”¨ã€‚")
        print("é”™è¯¯è¯¦æƒ…:", e)
        if detector and hasattr(detector, 'disable_profiler') and callable(detector.disable_profiler):
            detector.disable_profiler()
        return
    
    screen_manager.select_roi()
    if screen_manager.roi is None:
        print("ğŸ”´ æœªé€‰æ‹©æ¸¸æˆåŒºåŸŸï¼Œç¨‹åºé€€å‡ºã€‚")
        if detector and hasattr(detector, 'disable_profiler') and callable(detector.disable_profiler):
            detector.disable_profiler() 
        return

    print("3ç§’åæœºå™¨äººå°†å¼€å§‹è¿è¡Œ...")
    time.sleep(3)
    
    try:
        while True:
            frame_start_time = time.perf_counter()

            current_time = time.time()
            dt = current_time - prev_time
            if dt == 0: dt = 1/60
            prev_time = current_time 

            capture_start = time.perf_counter()
            img = screen_manager.capture()
            capture_end = time.perf_counter()
            if img is None: break
            
            detection_start = time.perf_counter()
            detections = detector.detect(img, yolo_class_names=['bird', 'cactus', 'dino'])
            detection_end = time.perf_counter()
            
            game_state_update_start = time.perf_counter()
            game_state.update(detections, dt)
            game_state_update_end = time.perf_counter()

            world_model_update_start = time.perf_counter()
            closest_obs = min(game_state.obstacles, key=lambda o: o[0][0]) if game_state.obstacles else None
            world_model.update(closest_obs, dt)
            world_model_update_end = time.perf_counter()
            
            state_build_start = time.perf_counter()
            state_vector = build_state_vector(game_state, world_model)
            state_build_end = time.perf_counter()

            # --- è¯Šæ–­ GameState, WorldModel, StateVector çš„å†…å®¹ ---
            print(f"DEBUG_DECISION: Dino Box: {game_state.dino_box}")
            print(f"DEBUG_DECISION: Obstacles Count: {len(game_state.obstacles)} | Closest: {closest_obs}")
            pos, speed = world_model.get_state()
            print(f"DEBUG_DECISION: World Model State (Pos, Speed): ({pos:.2f}, {speed:.2f})" if pos is not None else "DEBUG_DECISION: World Model State: None")
            print(f"DEBUG_DECISION: State Vector: {state_vector.round(3) if state_vector is not None else 'None'}")
            
            action_index = 0
            inference_start = time.perf_counter()
            if state_vector is not None:
                input_state_tensor = np.expand_dims(state_vector, axis=0).astype(np.float32)

                input_name = ort_session.get_inputs()[0].name
                output_name = ort_session.get_outputs()[0].name 

                raw_action_result = [] 
                try:
                    raw_action_result = ort_session.run([output_name], {input_name: input_state_tensor})
                except Exception as e:
                    print(f"âŒ ERROR: å†³ç­–æ¨¡å‹ (dino_policy.onnx) ORT run å¤±è´¥ï¼è¯¦ç»†é”™è¯¯: {e}")
                    print(f"  è¾“å…¥æ•°æ®å½¢çŠ¶: {input_state_tensor.shape}, ç±»å‹: {input_state_tensor.dtype}")
                    raw_action_result = [] 

                if raw_action_result and len(raw_action_result) > 0:
                    action_output_tensor = raw_action_result[0]
                    if isinstance(action_output_tensor, np.ndarray) and action_output_tensor.size > 0:
                        action_index = int(action_output_tensor.flatten()[0]) 
                        if action_index not in [0, 1, 2]:
                            print(f"âš ï¸ è­¦å‘Šï¼šå†³ç­–æ¨¡å‹è¿”å›äº†è¶…å‡ºèŒƒå›´çš„åŠ¨ä½œç´¢å¼•: {action_index}ã€‚é»˜è®¤æ‰§è¡Œ 'æ— æ“ä½œ'ã€‚")
                            action_index = 0
                    else:
                        print(f"âš ï¸ è­¦å‘Šï¼šå†³ç­–æ¨¡å‹è¿”å›é numpy æ•°ç»„æˆ–ç©ºæ•°ç»„ã€‚åŸå§‹ç»“æœ: {raw_action_result}ã€‚é»˜è®¤æ‰§è¡Œ 'æ— æ“ä½œ'ã€‚")
                        action_index = 0
                else:
                    print(f"âš ï¸ è­¦å‘Šï¼šå†³ç­–æ¨¡å‹æœªè¿”å›ä»»ä½•ç»“æœã€‚åŸå§‹ç»“æœ: {raw_action_result}ã€‚é»˜è®¤æ‰§è¡Œ 'æ— æ“ä½œ'ã€‚")
                    action_index = 0

            inference_end = time.perf_counter()

            # --- è¯Šæ–­å†³ç­–åŠ¨ä½œå’Œæ‰§è¡Œæƒ…å†µ ---
            print(f"DEBUG_DECISION: Chosen Action Index: {action_index}")

            action_execute_start = time.perf_counter()
            if action_index == 1:
                agent.jump(duration=0.05)
            elif action_index == 2:
                agent.duck()
            action_execute_end = time.perf_counter()

            frame_end_time = time.perf_counter()
            
            print(f"Frame Time: {((frame_end_time - frame_start_time)*1000):.2f}ms | "
                  f"Capture: {((capture_end - capture_start)*1000):.2f}ms | "
                  f"Detect: {((detection_end - detection_start)*1000):.2f}ms | "
                  f"GameState: {((game_state_update_end - game_state_update_start)*1000):.2f}ms | "
                  f"WorldModel: {((world_model_update_end - world_model_update_start)*1000):.2f}ms | "
                  f"StateBuild: {((state_build_end - state_build_start)*1000):.2f}ms | "
                  f"Inference: {((inference_end - inference_start)*1000):.2f}ms | "
                  f"ActionExecute: {((action_execute_end - action_execute_start)*1000):.2f}ms")

            debug_img = img.copy()
            for box, class_name in detections:
                x1, y1, x2, y2 = box
                color_map = {"dino": (0, 255, 0), "cactus": (0, 0, 255), "bird": (255, 0, 0)}
                color = next((c for k, c in color_map.items() if k in class_name), (0, 255, 255))
                cv2.rectangle(debug_img, (x1, y1), (x2, y2), color, 2)
                cv2.putText(debug_img, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            _, speed = world_model.get_state()
            speed_text = f"Speed: {speed or 0:.0f}"
            cv2.putText(debug_img, speed_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            cv2.imshow("Dino AI - Expert Brain (Debug View)", debug_img)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    finally:
        if detector and hasattr(detector, 'disable_profiler') and callable(detector.disable_profiler):
            detector.disable_profiler() 
            
    cv2.destroyAllWindows()
    print("ğŸ¤– Dino AI å·²åœæ­¢è¿è¡Œã€‚")
    
if __name__ == "__main__":
    main()